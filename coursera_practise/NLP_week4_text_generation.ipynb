{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "tensorflow_NLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praths007/tensorflow_certification/blob/master/coursera_practise/NLP_week4_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qmO6nyR5MGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOC7bVJa5OUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8411ee88-29c6-4944-bc51-cd1cab95429b"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2glVPyTN5XUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAvgPool1D, LSTM, Bidirectional, Embedding, Flatten\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960_NSPSvlBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "corpus = data.split('\\n')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiIk1Anivzdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "vocab = tokenizer.word_index\n",
        "\n",
        "n_gram_vocab = []\n",
        "for line in corpus:\n",
        "  sequence = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(sequence)):\n",
        "    n_grams = sequence[:i+1]\n",
        "    n_gram_vocab.append(n_grams)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1-60PdCwvLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = max([len(s) for s in n_gram_vocab])\n",
        "padded_seq = pad_sequences(n_gram_vocab, maxlen=maxlen, padding='pre')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhs5Qf4ezBEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2d16c882-857c-4ddb-b22a-d3af4e206437"
      },
      "source": [
        "padded_seq"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   4,   2],\n",
              "       [  0,   0,   0, ...,   4,   2,  66],\n",
              "       [  0,   0,   0, ...,   2,  66,   8],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  60, 262,  13],\n",
              "       [  0,   0,   0, ..., 262,  13,   9],\n",
              "       [  0,   0,   0, ...,  13,   9,  10]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skApE2pSyQft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = np.array(padded_seq[:,:-1])\n",
        "labels =  np.array(padded_seq[:,-1])\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvj72BbVzzlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bd867e1-dccf-4194-b032-c752d4099605"
      },
      "source": [
        "sentences.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(453, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWv-OMf-2j0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = int(len(sentences) * 0.8)\n",
        "\n",
        "train_sent = sentences[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "test_sent = sentences[train_size:]\n",
        "test_labels = labels[train_size:]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgFuZLKK3Mym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = to_categorical(test_labels)\n",
        "train_labels = to_categorical(train_labels)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6YXfLsH0Frf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ededa18-d1fa-472f-d3eb-cec7c460176d"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(453,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfUeIKgOzUQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "                    Embedding(10000, 64, input_length=train_sent.shape[1]),\n",
        "                    Bidirectional(LSTM(16)),\n",
        "                    Flatten(),\n",
        "                    Dense(128, activation='relu'),\n",
        "                    Dense(train_labels.shape[1], activation='softmax')\n",
        "\n",
        "])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kDOesVg0L5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "820e4f7c-612d-4b02-cb9b-38716c7900e1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 10, 64)            640000    \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 32)                10368     \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 217)               27993     \n",
            "=================================================================\n",
            "Total params: 682,585\n",
            "Trainable params: 682,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOoWBgt74x6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9ee2e04d-f956-4945-a982-16cab9fc0c17"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WZ6oR8L0hh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67ad673c-aa41-4076-9cbc-bda48f45898e"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_sent, train_labels, validation_data=[test_sent, test_labels], epochs=100)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 5.3757 - accuracy: 0.0221 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.3461 - accuracy: 0.0608 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.2595 - accuracy: 0.0552 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.0548 - accuracy: 0.0552 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.8838 - accuracy: 0.0552 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.8341 - accuracy: 0.0552 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.7973 - accuracy: 0.0470 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.7570 - accuracy: 0.0635 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.7094 - accuracy: 0.0580 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.6513 - accuracy: 0.0580 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.5819 - accuracy: 0.0718 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4992 - accuracy: 0.0746 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4186 - accuracy: 0.0856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.3070 - accuracy: 0.0994 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1833 - accuracy: 0.0884 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0477 - accuracy: 0.1050 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9078 - accuracy: 0.1298 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7815 - accuracy: 0.1271 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6499 - accuracy: 0.1547 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5401 - accuracy: 0.1630 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4299 - accuracy: 0.1657 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3179 - accuracy: 0.1713 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.2195 - accuracy: 0.1740 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.1085 - accuracy: 0.2182 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.0093 - accuracy: 0.2320 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.9156 - accuracy: 0.2265 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.8341 - accuracy: 0.2845 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.7388 - accuracy: 0.2680 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.6478 - accuracy: 0.3149 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.5685 - accuracy: 0.3232 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4947 - accuracy: 0.3343 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.4220 - accuracy: 0.3812 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.3709 - accuracy: 0.3702 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.2871 - accuracy: 0.3978 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.2145 - accuracy: 0.4337 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.1724 - accuracy: 0.4530 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.0807 - accuracy: 0.4834 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.0330 - accuracy: 0.4724 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.9636 - accuracy: 0.5276 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.9103 - accuracy: 0.5497 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.8478 - accuracy: 0.5249 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.7856 - accuracy: 0.5470 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.7440 - accuracy: 0.5829 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.6755 - accuracy: 0.6105 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.6298 - accuracy: 0.5994 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.5867 - accuracy: 0.6133 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.5230 - accuracy: 0.6519 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.4926 - accuracy: 0.6215 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.4544 - accuracy: 0.6657 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.4087 - accuracy: 0.6768 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.3593 - accuracy: 0.6878 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.3121 - accuracy: 0.7072 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.2801 - accuracy: 0.7182 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.2053 - accuracy: 0.7707 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.1806 - accuracy: 0.7597 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.1573 - accuracy: 0.7762 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.1185 - accuracy: 0.7514 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0576 - accuracy: 0.7873 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.0296 - accuracy: 0.8122 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9899 - accuracy: 0.8039 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.9568 - accuracy: 0.8287 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9386 - accuracy: 0.8094 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.9195 - accuracy: 0.8149 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.8980 - accuracy: 0.8122 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8658 - accuracy: 0.8453 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.8288 - accuracy: 0.8398 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8018 - accuracy: 0.8481 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.7816 - accuracy: 0.8508 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7604 - accuracy: 0.8619 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.7441 - accuracy: 0.8398 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.7150 - accuracy: 0.8536 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6764 - accuracy: 0.8646 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6540 - accuracy: 0.8757 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6324 - accuracy: 0.8923 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6142 - accuracy: 0.8867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5995 - accuracy: 0.8812 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5889 - accuracy: 0.8757 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5864 - accuracy: 0.8757 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5891 - accuracy: 0.8840 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.8840 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5403 - accuracy: 0.8867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5230 - accuracy: 0.8895 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5041 - accuracy: 0.8895 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4770 - accuracy: 0.9006 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4661 - accuracy: 0.9033 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4489 - accuracy: 0.9088 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4307 - accuracy: 0.9144 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4367 - accuracy: 0.9116 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4165 - accuracy: 0.9116 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3969 - accuracy: 0.9144 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3824 - accuracy: 0.9254 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3743 - accuracy: 0.9282 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3596 - accuracy: 0.9337 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3559 - accuracy: 0.9337 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3398 - accuracy: 0.9282 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3336 - accuracy: 0.9227 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3273 - accuracy: 0.9392 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3224 - accuracy: 0.9448 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3121 - accuracy: 0.9392 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2989 - accuracy: 0.9503 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fp61Op22eo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "50239066-31be-4570-9278-471f3e4f8ec6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "# plt.ylabel('accuracy')\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.ylabel('loss')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f73751977f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JvdeToZ2hdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}